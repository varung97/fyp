\documentclass[a4paper]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{relsize}
\usepackage[
  top    = 2.75cm,
  bottom = 3.00cm,
  left   = 2.50cm,
  right  = 2.50cm
]{geometry}
\setlength{\parindent}{0in}

\title{\texttt{Filter\_Clusters} improvements}

\begin{document}
    \maketitle

    \section{Preliminaries}
    Define:
    \begin{itemize}
        \item $T[u]$ for some tree $T$ and some node $u$ to be the subtree of $T$ rooted at $u$
        \item $\Lambda(T)$ for some tree $T$ to be the leaf set of $T$
        \item $T|C$ to be the tree $T$ restricted to the leaf set $C$, i.e. keep all common ancestors of $C$ while keeping the relative structure of these nodes the same as in the original tree
        \item $T||C$ to be a modified version of $T|C$. This version includes ``special nodes''. Given a parent-child pair in $T|C$ a special node is added between them if these nodes are not a parent-child pair in $T$; this special node represents all the nodes on the path between the pair in $T$
        \item Trees $T_A$ and $T_B$ on which the procedure \texttt{Filter\_Clusters} will be run
        \item Centroid path of $T_A$ to be $\pi$. Number the nodes from leaf to root from $1$ to $\alpha$
        \item Set of side trees created when $\pi$ is removed from $T_A$ to be $\sigma(\pi)$
        \item $k$ to be the total number of trees over which the frequency difference tree is being computed
        \item $n$ to be the size of the leaf set of each of these trees (each of which is the same)
        \item weight of a node $u$ in one of the trees under consideration to be the number of trees that its associated cluster appears in
    \end{itemize}

    \section{Bottlenecks}

    Note that there are two bottlenecks in \texttt{Filter\_Clusters}:
    \begin{itemize}
        \item Step 3 preprocesses $T_B$ in $O(n\;log\;n)$ time and then uses $\sum_{\tau\in\sigma(\pi)}O(|\Lambda(\tau)|log(|\Lambda(\tau)|))$ time to construct each $T_B||\Lambda(\tau)$.

        \item Step 6 involves making $O(n)$ add/remove operations on a BT of size $O(n)$, costing $O(n\;log\;n)$
    \end{itemize}

    \section{Step 3}

    First, to avoid preprocessing $T_B$ for RMQ queries within each recursive call, simply do it once at the beginning. We will now discuss how this original tree can be used to answer RMQ queries in recursive calls.\\

    Note that the RMQ structure can give us a handle to the node which has the max weight between two nodes. For some side tree $\tau$, when constructing $T_B||\Lambda(\tau)$ we add some special nodes $z$ to $T_B|\Lambda(\tau)$ which represent a node with max weight between some two nodes. These nodes should keep handles to the node in the original tree that they identify with. In recursive calls, if asked to construct a special node where one or both of the endpoints is/are special node(s), use the handle to the node in the original tree to make this query. That is, all RMQ queries are made against the original preprocessed tree.\\

    Constructing each $T_B|\Lambda(\tau)$ costs total $O(n)$ time [Original paper]. From each of these, contructing $T_B||\Lambda(\tau)$ will then cost $O(|\Lambda(\tau)|)$ time each since each tree contains $O(|\Lambda(\tau)|)$ edges and each RMQ query costs $O(1)$. Also, marking spoiled nodes can be done in $O(|\Lambda(\tau)|)$ time per $\tau$, by doing a bottom up traversal of the tree and counting the size of the leaf set.\\

    Thus step 3 can be completed in $O(n)$ time where $n$ is the size of the subproblem, along with a single preprocessing step at the start of the \texttt{Filter\_Clusters} subroutine, costing $O(n\;log\;n)$ time, where $n$ is the size of the leaf set.

    \section{Step 6}

    Let the data structure being used to store the incompatible nodes be $IDS$.\\

    Say \texttt{Filter\_Clusters}$(T_a, T_b)$ is being computed. Note that $T_b$ may have spoiled nodes. For any tree $T$, let $\pi(T)$ be the centroid path of $T$ and $|\pi(T)| = \alpha_T$.

    \textbf{Lemma 1:} Let $\tau \in \sigma(\pi(T_a))$ be some side tree in $T_a$. For any node $u$ that was removed from $IDS$ during the call to \texttt{Filter\_Clusters}$(\tau, T_b||\tau)$, $\Lambda(T_b[u]) \subseteq \Lambda(\tau)$.\\
    \textit{Proof:} Let the centroid path of $\tau$ be $\pi(\tau)$. Notice that when a node $u$ is removed from $IDS$, that means that for some node $q \in \pi(\tau)$, $counter(u) = |\Lambda(T_b||\tau[u]) \cap \Lambda(\tau[q])| = |\Lambda(T_b||\tau[u])|$ and $u$ is not spoiled. Since $u$ is not spoiled, $\Lambda(T_b||\tau[u]) = \Lambda(T_b[u])$. Thus $T_b[u] \subseteq \Lambda(\tau[q])$. Since $\Lambda(\tau[q]) \subseteq \Lambda(\tau)$, $T_b[u] \subseteq \Lambda(\tau)$.\\

    \textbf{Lemma 2:} If for some cluster $C$ and some side tree $\tau \in \sigma(\pi)$, $C \subseteq \Lambda(\tau)$ then $C$ is compatible with $T_a$.\\
    \textit{Proof:} Since the leaf sets of all sidetrees are mutually disjoint, and $C \subseteq \tau$, $C$ is disjoint with leaf sets of all other sidetrees, and so is compatible with all nodes in these. The only remaining nodes are those on the centroid path. Let $p_i \in \pi(T_a)$ be the node on the centroid path that is a direct parent of $\tau$. Then for any $j$ such that $1 \leq j < i$, $\Lambda(T_a[p_j])$ is mutually disjoint with $C$ and so these are compatible. For any $j$ such that $i \leq j \leq \alpha_{T_a}$, $\Lambda(T_a[p_i]) \subseteq \Lambda(T_a[p_j])$. Also, $\Lambda(\tau) \subseteq \Lambda(T_a[p_i])$. Thus $C$ is compatible with $p_j$.\\

    From Lemma 1 and 2, for any node $u$ and side tree $\tau \in \sigma(\pi(T_a))$, if $u$ was removed from $IDS$ during the call to \texttt{Filter\_Clusters}$(\tau, T_b||\tau)$, $\Lambda(T_b[u])$ is compatible with $T_a$. Then, we should never need to add $u$ to $IDS$ again. We detail below how this is ensured.\\

    Firstly, note that the nodes $u$ that are removed from $IDS$ during the recursive calls to \texttt{Filter\_Clusters} form disjoint subtrees of $T_b$ since their leaf sets are subsets of disjoint side trees. For each of these subtrees, we do not wish to iterate over the nodes in them again. Thus, we would like start from the parents of the roots of these trees (rather than the leaves as in the original algorithm). To do so, each call to \texttt{Filter\_Clusters} returns the parents of the roots of the subtrees discovered during its execution as a linked list.\\

    To achieve this, augment each node in $T_B$ with a property $parentOfSubtree$, initialised to $False$. When traversing $T_B$ upwards while removing nodes from $IDS$, for every removed node $x$, also check $parentOfSubtree(x)$. If this is $True$, then remove $x$ from the linked list and set it to $False$. When the loop terminates, if $x$ is not $root(T_B)$ and $parentOfSubtree(x)$ is $False$, then add $x$ to a linked list (keeping a pointer to this element in $x$) and set $parentOfSubtree(x) = True$. Notice that at the end of this process our linked list contains exactly the parent of every desired subtree.

    In fact, all the nodes in the subtree rooted at $u$ are compatible with $p_i$ since their clusters are all subsets of $\Lambda(T_B[u])$. This leads to the observation that the nodes that are inserted and then removed from the incompatibility tree form subtrees within $T_B$, where each of these subtrees is compatible with $p_i$. Note that when we handle $p_i$ in the \texttt{Filter\_Clusters} algorithm, we construct a set $D = \Lambda(T_A[p_i]) \;\backslash\; \Lambda(T_A[p_{i-1}])$ and then say that any node on the path from some $x \in D$ to $r_i$ could be incompatible with $p_i$. But in fact, we could instead start from the roots of the subtrees found while solving the subproblem for the side trees of $p_i$ since descendants of these roots are guaranteed to be compatible.\\

    The key idea here is noticing that the weights being stored in the BT are all integers, bounded by $k$. Thus we can utilise a more efficient data structure (in particular a vEB tree) to store these weights.\\

    Recall that a vEB tree can carry out findMax operations in $O(1)$ time and insert and delete operations in $O(log\;log\;m)$ time where $m$ is the largest possible integer being stored in the tree.\\

    Finally, we can also make use of the fact that the number of unique weights in a tree is bounded by $n$ since the number of internal nodes in a tree is bounded by $n - 1$ and all leaves have the same weight $= k$. This means that the number of unique weights in any tree is $min(n, k)$, so we can remap the weights to integers in the range $[1, min(n, k)]$.\\

    To carry out this remapping, construct a triplet for each internal node $u$ in the trees, of the form $(weight(u), \text{ pointer to u}, \text{ index of tree to which }u\text{ belongs})$. Counting sort all the triplets obtained by weight, taking $O(nk)$ time, since the number of triplets is bounded by $O(nk)$ and the number of unique weights is bounded by $k$. For each tree (with say index $i$), initialise an empty array of size $n$, $A_i$, along with an index $p_i = 0$. Iterate over the sorted array of triplets and for each entry $(w, u, i)$, if $A_i[p_i] \neq w$, then set $p_i = p_i + 1$, then $A_i[p_i] = w$. Also set $remapped\_weight(u) = p_i$. Note that the original $weight(u)$ can be recovered as $A_i[remapped\_weight(u)]$. Now for each tree, the weights are bounded by $O(min(n, k))$.\\

    Recall that the standard vEB tree only stores 0/1 to indicate membership and so cannot handle duplicate keys. To get around this issue, we use a modified version of the vEB tree that stores integers representing the duplicity of a key at its leaves. Then an insert operation causes the integer at that position to be incremented while delete decrements the integer (unless it was already $0$). Notice that the time complexity of operations remains unchanged. However, the space complexity changes. Since we're storing numbers in $[1, min(n, k)]$, the standard vEB tree would have space complexity $O(min(n, k))$. Now instead of storing a single bit per element at the leaves, we're storing an integer. The amount of space needed to store this is $log(\text{Max duplicity})$. Since a tree contains $O(n)$ nodes, the max duplicity is $O(n)$, thus the space complexity of our new vEB tree is $O(min(n, k)\;log\;n)$.\\

    Now as a preprocessing step, we create such a vEB tree. Since the vEB tree only stores duplicity of keys, we update a property $inTree(u)$ when a node $u$ is added or removed from the tree. This property is set to $False$ when an instance of \texttt{Filter\_Clusters} begins for all nodes in $T_B$ and to $False$ again before \texttt{Filter\_Clusters} returns. When running \texttt{Filter\_Clusters}, the same vEB tree is passed to each instance of the problem. To avoid some nodes already having been inserted into the tree, before the algorithm returns an answer, we use predecessor queries and delete operations on the vEB tree to clear it of all entries.\\

    To analyse the time complexity of this approach, note that we're still making $O(n)$ updates to the vEB tree (as claimed in the original paper), so time taken to do this is $O(n\;log\;log\;min(n, k))$. It costs $O(n)$ time to set $inTree$ to $False$ for every node at the beginning and end. In addition, clearing the vEB tree costs $O(n\;log\;log\;min(n, k))$ since a maximum of $O(n)$ values would be in the tree. Thus the time taken to carry out all of this is $O(n\;log\;log\;min(n, k))$.

    \section{Overall analysis}

    For \texttt{Filter\_Clusters},

    \[T(x) = O(x\;log\;log\;min(n, k)) + \sum_{\tau\in\sigma(\pi)}T(|\Lambda(\tau)|)\]

    Since there are $O(log\;n)$ recursion levels,
    \[T(n) = O(n\;(log\;n)\;(log\;log\;min(n, k)))\]

    Note that the preprocessing step for remapping is only run once during the entire \texttt{Frequency\_Difference} algorithm. Recall that time complexity of \texttt{Frequency\_Difference} $= O(kn\;log\;n) + O(k \cdot f(n, k)) + \text{Preprocessing}$, where $f(n, k)$ is the is the runtime of \texttt{Filter\_Clusters}. Thus for \texttt{Frequency\_Difference},
    \begin{align*}
        T(n) &= O(kn\;log\;n) + O(k \cdot n\;(log\;n)\;(log\;log\;min(n, k))) + O(kn)\\
        &= O(kn\;(log\;n)\;(log\;log\;min(n, k)))
    \end{align*}
\end{document}
